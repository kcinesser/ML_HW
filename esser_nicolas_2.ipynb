{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"text-decoration:underline;\">Problem 1: Distance and Norms</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine(a = [], b =[]):\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Cosine similarity is the similarity between two non-zero vectors that measures the inner product of the distance between the two vectors. It is a measurment of orientation, not magnitude.\n",
    "\n",
    "2) A cosine similarity of 0 would mean the two vectors are oriented 90 degress to each other.\n",
    "\n",
    "3) A similarity of 1 means the vectors are oriented the same, -1 means they are opposite each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([1,2])\n",
    "x2 = np.array([2,4])\n",
    "x3 = np.array([2,-1])\n",
    "x4 = np.array([np.random.randint(-10,10), np.random.randint(-10,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1 = cosine(x1, x2)\n",
    "sim2 = cosine(x1, x3)\n",
    "sim3 = cosine(x1, x4)\n",
    "\n",
    "print(\"The cosine similarity of %s and %s is %s.\" % (x1, x2, sim1))\n",
    "print(\"The cosine similarity of %s and %s is %s.\" % (x1, x3, sim2))\n",
    "print(\"The cosine similarity of %s and %s is %s.\" % (x1, x4, sim3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "V = np.array([x1, x2, x3, x4])\n",
    "origin = [0], [0] # origin point\n",
    "\n",
    "plt.quiver(*origin, V[:,0], V[:,1], color=['r','b','g','y'], scale=21)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4_L1 = norm(x4, 1)\n",
    "x4_L2 = norm(x4, 2)\n",
    "x4_L4 = norm(x4, 4)\n",
    "x4_L10 = norm(x4, 10)\n",
    "\n",
    "print(x4)\n",
    "print(\"L1: %s\" % x4_L1)\n",
    "print(\"L2: %s\" % x4_L2)\n",
    "print(\"L4: %s\" % x4_L4)\n",
    "print(\"L10: %s\" % x4_L10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_x4_L1 = norm(x4 - x1, 1)\n",
    "x1_x4_L2 = norm(x4 - x1, 2)\n",
    "x1_x4_L4 = norm(x4 - x1, 4)\n",
    "x1_x4_L10 = norm(x4 - x1, 10)\n",
    "\n",
    "print(\"x1 = %s, x4 = %s\" % (x1, x4))\n",
    "print(\"L1: %s\" % x1_x4_L1)\n",
    "print(\"L2: %s\" % x1_x4_L2)\n",
    "print(\"L4: %s\" % x1_x4_L4)\n",
    "print(\"L10: %s\" % x1_x4_L10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"text-decoration:underline;\">Problem 2: Rank, Matrix Inverses, and Solving Linear Systems</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(402)\n",
    "\n",
    "mat = np.random.uniform(-10,11,(3,3))\n",
    "print(mat)\n",
    "print(\"Rank: %s\" % np.linalg.matrix_rank(mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an nxn matrix, if the rank of that matrix is < n, then the inverse does not exist. The rank of a matrix is the number of lineraly independant columns, meaning that if rank = n, then the matrix is consistent, and is therefore invertible. Likewise, this matrix spans the dimension of the rank, in this case R<sup>3</sup>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = np.linalg.inv(mat)\n",
    "print(inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.matmul(inv, np.array([1,2,3]))\n",
    "print(b)\n",
    "\n",
    "x = np.matmul(mat, b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.linalg.solve(mat, np.array([1,2,3]))\n",
    "print(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newMat = np.array([[1,-1,1], [-3,2,4],[-1,0,6]])\n",
    "newMatRank = np.linalg.matrix_rank(newMat)\n",
    "newMatInv = np.linalg.inv(newMat)\n",
    "mult = np.matmul(newMat, newMatInv)\n",
    "newMatX = np.linalg.solve(newMat, np.array([1,2,3]))\n",
    "\n",
    "print(newMat)\n",
    "print(\"Rank: %s\" % newMatRank)\n",
    "print(\"Inverse:\\n %s\" % newMatInv)\n",
    "print(\"newMat*newMatInv:\\n %s\" % mult)\n",
    "print(\"x: %s\" % newMatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When designing a machine learning algorithm, you may not always get data that won't give errors, so it is important to validate data. For example, make sure your matrix can be invertible before trying to calculate inverses, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx = np.linalg.lstsq(newMat, np.array([1,2,3]), rcond=None)[0]\n",
    "print(approx)\n",
    "b_hat = np.matmul(newMat, approx)\n",
    "print(b_hat)\n",
    "dist = norm(b_hat-np.array([1,2,3]))\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"text-decoration: underline;\">Problem 3: Determinants, Eigenvalues, and Positive Definite Matrices</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(88)\n",
    "\n",
    "mat2 = 10 * np.random.randn(3,3) + 5\n",
    "var = np.var(mat2)\n",
    "mean = mat2.mean()\n",
    "\n",
    "print(mat2)\n",
    "print(var)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det = np.linalg.det(mat2)\n",
    "print(\"Det: %s\" % det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The determinant can be viewed as the volume scaling factor when considering the linear transformation the matrix represents. If the transformation reverse the orientation of the space, the determinant will be negative. If the determinant of the matrix is 0, then the matrix is not invertible, meaning it does not span the space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig = np.linalg.eig(mat2)\n",
    "\n",
    "print(eig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An eigenvector is a vector that represents the direction that is stretched by the linear transformation represented by the matrix, and the eigenvalue is the factor of that stretch. If an eigenvalue is 0, again, it means the matrix is not invertible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
